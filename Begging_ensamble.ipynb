{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6f1efe",
   "metadata": {},
   "source": [
    "# Bagging Ensemble (Bootstrap Aggregating)\n",
    "\n",
    "## ðŸ§  What is Bagging?\n",
    "\n",
    "**Bagging (Bootstrap Aggregating)** is an ensemble method that:\n",
    "\n",
    "1. Trains multiple models (usually the same algorithm, e.g. Decision Trees)\n",
    "2. On different random subsets of the training data (sampled with replacement)\n",
    "3. Combines their predictions (by averaging for regression or voting for classification)\n",
    "\n",
    "### ðŸ’¬ In short:\n",
    "\n",
    "> \"Train many weak models on slightly different data â†’ average or vote â†’ stronger, more stable model.\"\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“˜ How It Improves Accuracy\n",
    "\n",
    "- **Reduces variance** (overfitting)\n",
    "- **Doesn't change bias** (average prediction) much\n",
    "- **Works well with unstable models** like decision trees\n",
    "- Each tree sees slightly different data â†’ different errors â†’ averaging cancels them out\n",
    "\n",
    "### Mathematically:\n",
    "\n",
    "$$\\text{Var}(\\bar{f}) = \\frac{1}{M^2} \\sum_{i=1}^{M} \\text{Var}(f_i) \\approx \\frac{1}{M} \\text{Var}(f)$$\n",
    "\n",
    "â†’ The more estimators ($M$), the lower the variance.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ Key Parameters\n",
    "\n",
    "| Parameter            | Description                                |\n",
    "| -------------------- | ------------------------------------------ |\n",
    "| `estimator`          | Base model (e.g. DecisionTreeClassifier)   |\n",
    "| `n_estimators`       | Number of models in the ensemble           |\n",
    "| `max_samples`        | Fraction or number of samples per model    |\n",
    "| `max_features`       | Fraction or number of features per model   |\n",
    "| `bootstrap`          | Sampling with replacement (True = Bagging) |\n",
    "| `bootstrap_features` | If True, random feature subsets too        |\n",
    "| `n_jobs`             | Use multiple CPU cores                     |\n",
    "| `oob_score`          | \"Out-of-bag\" score (built-in validation)   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb10ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f022c87",
   "metadata": {},
   "source": [
    "## Step 1: Load Dataset and Split\n",
    "\n",
    "We'll use the Iris dataset to demonstrate bagging classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb10ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "x, y = data.data, data.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4066471a",
   "metadata": {},
   "source": [
    "## Step 2: Create Bagging Ensemble\n",
    "\n",
    "We create a `BaggingClassifier` with:\n",
    "- **Base estimator**: Decision Tree (weak learner)\n",
    "- **50 estimators**: 50 different trees trained on different bootstrap samples\n",
    "- **max_samples=0.8**: Each tree sees 80% of the training data\n",
    "- **bootstrap=True**: Samples are drawn with replacement (this is what makes it \"bagging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8633e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Base model (weak learner)\n",
    "base_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "# Bagging ensemble\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=base_tree,\n",
    "    n_estimators=50,       # number of trees\n",
    "    max_samples=0.8,       # each tree sees 80% of data\n",
    "    bootstrap=True,        # sample with replacement\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f464d9",
   "metadata": {},
   "source": [
    "## Step 3: Train and Evaluate\n",
    "\n",
    "Train the bagging ensemble and evaluate its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b2cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "bag_model.fit(x_train, y_train)\n",
    "y_pred = bag_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Bagging Classifier Accuracy: {accuracy:.2f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
